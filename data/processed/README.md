# Processed Data Directory

This directory contains cleaned and processed data files generated by the preprocessing scripts.

## Files

After running `scripts/data_preprocessing.py`, you'll find:

- `stress_data_processed.csv` - Main processed dataset with:
  - Cleaned and imputed missing values
  - Encoded categorical variables
  - Scaled numeric features
  - Derived features (academic_pressure, mental_health_composite, wellness_index)

## Data Processing Steps

1. **Missing Value Imputation**: Numeric (mean) and categorical (mode) imputation
2. **Categorical Encoding**: Label encoding for categorical variables
3. **Feature Scaling**: Standardization of numeric features
4. **Feature Engineering**: Creation of composite and derived features
5. **Validation**: Data quality checks and summary statistics

## Usage

Processed data files are used as input for:
- Causal inference analysis
- IRT modeling
- Classification and clustering
- NLP analysis

## Notes

- Processed data is generated automatically - no manual intervention needed
- If processing parameters change, regenerate this data by re-running the preprocessing script
- Data format is maintained for compatibility across all analysis modules
